from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List, Dict
from pathlib import Path as FilePath
from datetime import datetime, timezone

from app.database import get_db
from app import models, schemas
from app.schemas import ArtifactType

##########################################################################
#
# Globals
#
##########################################################################

router = APIRouter()

DATA_ROOT = FilePath("/data/ML/big-data-full")

# Map filename patterns to artifact_type strings
# NOTE: visit https://github.com/aryrfjr/PRM_4_113603/tree/main/scripts for
#   more information on the .sh scripts mentioned below.
EXPECTED_RUN_ARTIFACTS = {  # NOTE: use template.format(NC=nominal_composition)
    "zca-th300.dump": ArtifactType.LAMMPS_DUMP,  # generated by zca-bd-full-SD-cpu.sh; Run
    "log.lammps": ArtifactType.LAMMPS_LOG,  # generated by zca-bd-full-SD-cpu.sh; Run
    "{NC}.lmp.inp": ArtifactType.LAMMPS_INPUT,  # generated by zca-bd-full-SD-cpu.sh; Run
    "{NC}.lmp.out": ArtifactType.LAMMPS_OUTPUT,  # generated by zca-bd-full-SD-cpu.sh; Run
}

EXPECTED_SUB_RUN_ARTIFACTS = {  # NOTE: use template.format(NC=nominal_composition)
    "{NC}.scf.in": ArtifactType.QE_SCF_IN,  # generated by setup_ICOHP_jobs.py
    "{NC}.xyz": ArtifactType.LAMMPS_DUMP_XYZ,  # generated by setup_ICOHP_jobs.py
    "lobsterin": ArtifactType.LOBSTER_INPUT,  # generated by setup_ICOHP_jobs.py
    "lobsterin-quippy": ArtifactType.LOBSTER_INPUT_BND,  # generated by setup_ICOHP_jobs.py
    "SOAPS.vec": ArtifactType.SOAP_VECTORS,  # generated by setup_ICOHP_jobs.py
    "{NC}.scf.out": ArtifactType.QE_SCF_OUT,  # generated by zca-QE-SD_cpu.sh
    "lobsterout": ArtifactType.LOBSTER_RUN_OUTPUT,  # generated by zca-LOB-SD_cpu.sh
    "{NC}.lb.out": ArtifactType.LOBSTER_OUTPUT,  # generated by zca-LOB-SD_cpu.sh
    "ICOHPLIST.lobster": ArtifactType.ICOHPLIST,  # generated by zca-LOB-SD_cpu.sh
}

##########################################################################
#
# Helpers
#
##########################################################################


#
# Register known artifact files in sub_run_path and registers them in the DB.
#
##########################################################################
def register_artifacts(
    nominal_composition: str,
    path: FilePath,
    expected_artifacts: Dict,
) -> List[
    models.SimulationArtifact
]:  # each element in the returned List is an SQLAlchemy ORM object

    artifacts = []

    for filename, artifact_type in expected_artifacts.items():

        file_path = path / filename.format(NC=nominal_composition)

        if file_path.exists():

            artifact = models.SimulationArtifact(
                artifact_type=artifact_type.value,
                file_path=str(file_path),
                file_size=file_path.stat().st_size,
                checksum=None,  # TODO: compute SHA256 here
                created_at=datetime.now(timezone.utc),
            )

            artifacts.append(artifact)

    return artifacts


#
# Detects known artifact files in sub_run_path and registers them in the DB.
#
##########################################################################
def detect_and_register_artifacts(
    nominal_composition: str,
    sub_run_number: int,
    run_path: FilePath,
    sub_run_path: FilePath,
) -> List[
    models.SimulationArtifact
]:  # each element in the returned List is an SQLAlchemy ORM object

    artifacts = []

    # NOTE: I was going to define a new table to separate artifacts related
    #   to Runs and SubRuns, but I decided to simply make SubRun 0 to have
    #   additional artifacts related to the LAMMPS simulations, since that
    #   SubRun is the reference structure.
    if sub_run_number == 0:

        artifacts.extend(
            register_artifacts(nominal_composition, run_path, EXPECTED_RUN_ARTIFACTS)
        )

    artifacts.extend(
        register_artifacts(
            nominal_composition, sub_run_path, EXPECTED_SUB_RUN_ARTIFACTS
        )
    )

    return artifacts


##########################################################################
#
# Endpoints for different resources types and scopes
#
# TODO: review status codes.
#
# TODO: review error handling: consistent and descriptive error responses,
#  with machine-readable codes and human-readable messages.
#
# TODO: Authentication (API key or OAuth2 support).
#
# TODO: Event-driven trigger (API could emit events, like job completed,
#  to Airflow or MLflow to trigger downstream tasks.
#
##########################################################################


#
# CRUD for DB table nominal_compositions
#
########################################################################


# Create Nominal Composition
@router.post(
    "/nominal_compositions/",
    response_model=schemas.NominalCompositionResponse,
    status_code=status.HTTP_201_CREATED,
    tags=["CRUD"],
)
def create_nominal_composition(
    payload: schemas.NominalCompositionCreate, db: Session = Depends(get_db)
):

    existing = db.query(models.NominalComposition).filter_by(name=payload.name).first()

    if existing:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Nominal composition '{payload.name}' already exists.",
        )

    nc = models.NominalComposition(
        name=payload.name,
        description=payload.description,
        created_at=datetime.now(timezone.utc),
    )

    db.add(nc)
    db.commit()
    db.refresh(nc)

    return schemas.NominalCompositionResponse.from_orm(nc)


# Get Nominal Composition by Name
@router.get(
    "/nominal_compositions/{name}",
    response_model=schemas.NominalCompositionResponse,
    tags=["CRUD"],
)
def get_nominal_composition(name: str, db: Session = Depends(get_db)):

    nc = db.query(models.NominalComposition).filter_by(name=name).first()

    if not nc:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Nominal composition '{name}' not found.",
        )

    return schemas.NominalCompositionResponse.from_orm(nc)


# List All Nominal Compositions
@router.get(
    "/nominal_compositions/",
    response_model=List[schemas.NominalCompositionResponse],
    tags=["CRUD"],
)
def list_nominal_compositions(db: Session = Depends(get_db)):

    ncs = (
        db.query(models.NominalComposition)
        .order_by(models.NominalComposition.name)
        .all()
    )

    return [schemas.NominalCompositionResponse.from_orm(nc) for nc in ncs]


# Update Nominal Composition
@router.put(
    "/nominal_compositions/{name}",
    response_model=schemas.NominalCompositionResponse,
    tags=["CRUD"],
)
def update_nominal_composition(
    name: str, payload: schemas.NominalCompositionUpdate, db: Session = Depends(get_db)
):

    nc = db.query(models.NominalComposition).filter_by(name=name).first()

    if not nc:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Nominal composition '{name}' not found.",
        )

    if payload.name:
        nc.name = payload.name
    if payload.description is not None:
        nc.description = payload.description

    db.commit()
    db.refresh(nc)

    return schemas.NominalCompositionResponse.from_orm(nc)


# Delete Nominal Composition
@router.delete(
    "/nominal_compositions/{name}",
    status_code=status.HTTP_204_NO_CONTENT,
    tags=["CRUD"],
)
def delete_nominal_composition(name: str, db: Session = Depends(get_db)):

    nc = db.query(models.NominalComposition).filter_by(name=name).first()

    if not nc:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Nominal composition '{name}' not found.",
        )

    db.delete(nc)
    db.commit()

    return None


#
# Endpoints scoped to the Data Generation & Labeling (DataOps) phase,
# which includes the following steps:
#
# - Generate (DataOps phase; exploration/exploitation)
# - ETL model (DataOps phase; Feature Store Lite)
#
########################################################################


# Schedules configuration space exploration for a given nominal composition
@router.post(
    "/generate/{nominal_composition}",
    response_model=schemas.GenericStatusResponse,
    status_code=status.HTTP_202_ACCEPTED,
    tags=["DataOps"],
)
def schedule_exploration(
    nominal_composition: str,
    payload: schemas.ScheduleExplorationRequest,
    db: Session = Depends(get_db),
):

    for i in range(payload.num_simulations):

        #
        # Check that the NominalComposition exists
        #
        ########################################################################
        nc = (
            db.query(models.NominalComposition)
            .filter_by(name=nominal_composition)
            .first()
        )

        if not nc:
            raise HTTPException(
                status_code=404,
                detail=f"NominalComposition '{nominal_composition}' not found",
            )

        #
        # Checking if we have a 100-atom cell for the next Run
        #
        ########################################################################

        last_run = (
            db.query(models.Run)
            .filter(models.Run.nominal_composition_id == nc.id)
            .order_by(models.Run.run_number.desc())
            .first()
        )

        next_run_number = (last_run.run_number if last_run else 0) + 1

        # TODO: handle gaps in the sequence of ID_RUN directories
        nc_dir = DATA_ROOT / nc.name
        nc_id_run_dir = nc_dir / "c/md/lammps/100" / str(next_run_number)
        nc_sub_run_dir = nc_id_run_dir / "2000/0"

        if not nc_dir.exists():
            raise HTTPException(
                status_code=404,
                detail=f"Directory for Nominal Composition '{nc.name}' not found",
            )

        if not nc_id_run_dir.exists() or not nc_sub_run_dir.exists():
            raise HTTPException(
                status_code=404,
                detail=f"Directory for ID_RUN '{next_run_number}' or for SUB_RUN '0' not found for Nominal Composition '{nc.name}'",
            )

        #
        # Persisting to the DB
        #
        ########################################################################

        # Create the SimulationArtifacts of default SubRun with id 0
        artifacts = detect_and_register_artifacts(
            nc.name, 0, nc_id_run_dir, nc_sub_run_dir
        )

        # Create the default SubRun with id 0
        sub_run = models.SubRun(
            sub_run_number=0,
            simulation_artifacts=artifacts,
            status=schemas.Status.SCHEDULED.value,  # optional: default already
        )

        # Create the Run and attach the SubRun
        run = models.Run(
            nominal_composition_id=nc.id,
            run_number=next_run_number,
            status=schemas.Status.SCHEDULED.value,  # optional
            sub_runs=[sub_run],  # ORM relationship binds them
        )

        # Persist both Run and SubRun with its SimulationArtifacts
        db.add(run)
        db.commit()
        db.refresh(run)

    return schemas.GenericStatusResponse(
        message=f"Exploration scheduled for '{nominal_composition}'.",
        status=schemas.Status.SCHEDULED.value,
    )


# Schedules geometry augmentation (exploitation) for a given nominal composition and runs
@router.post(
    "/generate/{nominal_composition}/{id_run}/augment",
    response_model=schemas.GenericStatusResponse,
    status_code=status.HTTP_202_ACCEPTED,
    tags=["DataOps"],
)  # TODO: set of id_runs and corresponding augmentation types in the request payload
def schedule_augmentation(
    nominal_composition: str, id_run: str, db: Session = Depends(get_db)
):

    return schemas.GenericStatusResponse(
        message=f"Augmentation scheduled for '{nominal_composition}', run '{id_run}'.",
        status=schemas.Status.SCHEDULED.value,
    )


# Schedules ETL model (DBI building) for a given nominal composition
@router.post(
    "/etl-model",
    response_model=schemas.ETLModelResponse,
    status_code=status.HTTP_202_ACCEPTED,
    tags=["DataOps"],
)
def schedule_etl_model(payload: schemas.ETLModelRequest, db: Session = Depends(get_db)):

    # NOTE: The ETL model is a two step process originally implemented with the
    # scripts 'create_SSDB.py' (for a single NC) and 'mix_SSDBs.py' (for multiple NCs).
    #
    # TODO: update the request payload to meet that reality.

    return schemas.ETLModelResponse(
        message=f"ETL model build scheduled for '{payload.nominal_composition}'.",
        status=schemas.Status.SCHEDULED.value,
    )


#
# Endpoints scoped to the Model Development (ModelOps) phase,
# which includes the single step:
#
# - Train/Tune (observability or model evaluation in the ModelOps phase)
#
########################################################################


# Schedules model evaluation for a given model and test set.
@router.post(
    "/evaluate",
    response_model=schemas.EvaluateModelResponse,
    status_code=status.HTTP_202_ACCEPTED,
    tags=["ModelOps"],
)
def schedule_model_evaluation(
    payload: schemas.EvaluateModelRequest, db: Session = Depends(get_db)
):

    return schemas.EvaluateModelResponse(
        message=f"Evaluation scheduled for model '{payload.model_name}' on test set '{payload.test_set}'.",
        status=schemas.Status.SCHEDULED.value,
    )


#
# Miscellaneous
#
########################################################################


@router.get("/ping", response_model=schemas.PingResponse, tags=["Misc"])
def ping():
    return {"message": "PING OK"}
